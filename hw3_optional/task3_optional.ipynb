{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a50e9973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Edu_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MH_Diag_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQDG_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQAN_sum_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQ_ANH_sum_T1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Neuro_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Extra_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ExtraAgT1_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ExtraComT1_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age_T2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQDG_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQAN_sum_T2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQ_ANH_sum_T2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age_T3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MH_Diag_T3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQDG_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQAN_sum_T3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQ_ANH_sum_T3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age_T4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQ_ANH_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQAN_sum_T4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASQ_ANH_sum_T4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age_T1_group",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "76368861-ce84-4a92-886f-1b780ccc6354",
       "rows": [
        [
         "0",
         "1",
         "19",
         "2.0",
         "1",
         "2",
         "1.125",
         "2.0",
         "2.375",
         "9",
         "20",
         "19",
         "1.52939",
         "3.68611",
         "3.666666667",
         "4.0",
         "19",
         "1.625",
         "1.0",
         "1.75",
         "13",
         "10",
         "14",
         "19",
         "2",
         "1.0",
         "1.1",
         "2.25",
         "8",
         "11",
         "18",
         "19",
         "2.5",
         "1.5",
         "1.2",
         "12",
         "12",
         "20",
         "17-20"
        ],
        [
         "1",
         "2",
         "20",
         "1.0",
         "1",
         "2",
         "2.75",
         "1.6",
         "3.75",
         "22",
         "16",
         "30",
         "2.94727",
         "3.90833",
         "4.266666667",
         "3.666666667",
         "20",
         "2.625",
         "1.0",
         "2.5",
         "21",
         "10",
         "20",
         "20",
         "2",
         "1.875",
         "1.9",
         "2.75",
         "15",
         "19",
         "22",
         "20",
         "4.0",
         "2.125",
         "1.2",
         "17",
         "12",
         "32",
         "17-20"
        ],
        [
         "2",
         "5",
         "23",
         "1.0",
         "1",
         "1",
         "1.5",
         "1.1",
         "2.0",
         "12",
         "11",
         "16",
         "2.92712",
         "2.96211",
         "3.4",
         "2.5",
         "23",
         "1.5",
         "1.6",
         "2.0",
         "12",
         "16",
         "16",
         "23",
         "1",
         "1.625",
         "1.2",
         "2.375",
         "13",
         "12",
         "19",
         "24",
         "3.125",
         "1.875",
         "1.7",
         "15",
         "17",
         "25",
         ">23"
        ],
        [
         "3",
         "6",
         "24",
         "2.0",
         "3",
         "2",
         "4.0",
         "1.6",
         "3.75",
         "32",
         "16",
         "30",
         "2.79687",
         "3.43711",
         "3.6",
         "3.222222222",
         "24",
         "2.0",
         "1.4",
         "1.5",
         "16",
         "14",
         "12",
         "24",
         "2",
         "4.5",
         "2.4",
         "3.125",
         "36",
         "24",
         "25",
         "25",
         "4.125",
         "3.25",
         "1.1",
         "26",
         "11",
         "33",
         ">23"
        ],
        [
         "4",
         "7",
         "19",
         "1.0",
         "1",
         "2",
         "1.5",
         "1.0",
         "2.5",
         "12",
         "10",
         "20",
         "2.23465",
         "2.51389",
         "2.2",
         "2.833333333",
         "19",
         "1.5",
         "1.1",
         "2.875",
         "12",
         "11",
         "23",
         "19",
         "2",
         "1.75",
         "1.0",
         "3.25",
         "14",
         "10",
         "26",
         "20",
         "4.0",
         "2.875",
         "1.0",
         "23",
         "10",
         "32",
         "17-20"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age_T1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Edu_T1</th>\n",
       "      <th>MH_Diag_T1</th>\n",
       "      <th>MASQDG_mean_T1</th>\n",
       "      <th>MASQAN_mean_T1</th>\n",
       "      <th>MASQ_ANH_mean_T1</th>\n",
       "      <th>MASQDG_sum_T1</th>\n",
       "      <th>MASQAN_sum_T1</th>\n",
       "      <th>...</th>\n",
       "      <th>MASQAN_sum_T3</th>\n",
       "      <th>MASQ_ANH_sum_T3</th>\n",
       "      <th>Age_T4</th>\n",
       "      <th>MASQ_ANH_mean_T4</th>\n",
       "      <th>MASQDG_mean_T4</th>\n",
       "      <th>MASQAN_mean_T4</th>\n",
       "      <th>MASQDG_sum_T4</th>\n",
       "      <th>MASQAN_sum_T4</th>\n",
       "      <th>MASQ_ANH_sum_T4</th>\n",
       "      <th>Age_T1_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.375</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>17-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.750</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.750</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.2</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>17-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>3.125</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.7</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>&gt;23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.750</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>4.125</td>\n",
       "      <td>3.250</td>\n",
       "      <td>1.1</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>&gt;23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>17-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age_T1  Gender  Edu_T1  MH_Diag_T1  MASQDG_mean_T1  MASQAN_mean_T1  \\\n",
       "0   1      19     2.0       1           2           1.125             2.0   \n",
       "1   2      20     1.0       1           2           2.750             1.6   \n",
       "2   5      23     1.0       1           1           1.500             1.1   \n",
       "3   6      24     2.0       3           2           4.000             1.6   \n",
       "4   7      19     1.0       1           2           1.500             1.0   \n",
       "\n",
       "   MASQ_ANH_mean_T1  MASQDG_sum_T1  MASQAN_sum_T1  ...  MASQAN_sum_T3  \\\n",
       "0             2.375              9             20  ...             11   \n",
       "1             3.750             22             16  ...             19   \n",
       "2             2.000             12             11  ...             12   \n",
       "3             3.750             32             16  ...             24   \n",
       "4             2.500             12             10  ...             10   \n",
       "\n",
       "   MASQ_ANH_sum_T3  Age_T4  MASQ_ANH_mean_T4  MASQDG_mean_T4  MASQAN_mean_T4  \\\n",
       "0               18      19             2.500           1.500             1.2   \n",
       "1               22      20             4.000           2.125             1.2   \n",
       "2               19      24             3.125           1.875             1.7   \n",
       "3               25      25             4.125           3.250             1.1   \n",
       "4               26      20             4.000           2.875             1.0   \n",
       "\n",
       "   MASQDG_sum_T4  MASQAN_sum_T4  MASQ_ANH_sum_T4  Age_T1_group  \n",
       "0             12             12               20         17-20  \n",
       "1             17             12               32         17-20  \n",
       "2             15             17               25           >23  \n",
       "3             26             11               33           >23  \n",
       "4             23             10               32         17-20  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "\n",
    "df = pd.read_csv('Data_MASQLong.csv')\n",
    "\n",
    "# number of observations and variables, variables’ measurement scale\n",
    "warnings.filterwarnings('ignore')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c281b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Edu_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MH_Diag_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_sum_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_sum_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neuro_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Extra_T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ExtraAgT1_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ExtraComT1_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_sum_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_sum_T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MH_Diag_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_sum_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_sum_T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_mean_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQDG_sum_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQAN_sum_T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MASQ_ANH_sum_T4",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2635b4a1-45e6-43cd-84f1-340efea9acfd",
       "rows": [
        [
         "count",
         "231.0",
         "231.0",
         "229.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0",
         "231.0"
        ],
        [
         "mean",
         "162.02597402597402",
         "21.943722943722943",
         "1.3056768558951966",
         "1.3506493506493507",
         "1.774891774891775",
         "2.2745052813852817",
         "1.7728715584415586",
         "2.800788484848485",
         "18.147186147186147",
         "17.653679653679653",
         "22.350649350649352",
         "2.872575238095238",
         "3.240788614718614",
         "3.3134199134458875",
         "3.2453102452943723",
         "22.11255411255411",
         "2.186456406926407",
         "1.7642616450216448",
         "2.7787569696969694",
         "17.432900432900432",
         "17.6017316017316",
         "22.186147186147185",
         "22.324675324675326",
         "1.7619047619047619",
         "2.0214130735930738",
         "1.656277012987013",
         "2.6822047186147184",
         "16.11255411255411",
         "16.536796536796537",
         "21.4025974025974",
         "22.48051948051948",
         "3.083472510822511",
         "2.2949391341991343",
         "1.6665223809523808",
         "18.25974025974026",
         "16.606060606060606",
         "24.61038961038961"
        ],
        [
         "std",
         "113.90865608509462",
         "4.10951620884164",
         "0.4617027034228476",
         "0.8145348168217206",
         "0.41856053686296085",
         "1.042251527789627",
         "0.8317250441060512",
         "0.770622243761973",
         "8.324661024825097",
         "8.215651651174957",
         "6.144844924139895",
         "0.6803831758545484",
         "0.5264704191440626",
         "0.6145166532287991",
         "0.6331564281449078",
         "4.124725863393354",
         "1.0081253817270206",
         "0.8013740141341346",
         "0.7640768410432314",
         "8.03435827277205",
         "8.020994004149715",
         "6.135072258174688",
         "4.151819585722443",
         "0.4268426138253134",
         "0.9631483888859261",
         "0.7415663154861118",
         "0.73289941460214",
         "7.667286122978868",
         "7.433016015354043",
         "5.838983846064478",
         "4.1429155547976215",
         "0.774054977008132",
         "0.9863293203776506",
         "0.7311558475098073",
         "7.8580934695204485",
         "7.31857420039899",
         "6.246715681385339"
        ],
        [
         "min",
         "1.0",
         "17.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "7.0",
         "9.0",
         "8.0",
         "1.33495",
         "1.51389",
         "1.266666667",
         "1.222222222",
         "18.0",
         "1.0",
         "1.0",
         "1.0",
         "7.0",
         "9.0",
         "8.0",
         "18.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "7.0",
         "9.0",
         "8.0",
         "18.0",
         "1.125",
         "1.0",
         "1.0",
         "7.0",
         "6.0",
         "9.0"
        ],
        [
         "25%",
         "71.5",
         "20.0",
         "1.0",
         "1.0",
         "2.0",
         "1.375",
         "1.1",
         "2.25",
         "11.0",
         "11.0",
         "18.0",
         "2.3896",
         "2.94911",
         "2.933333333",
         "2.833333333",
         "20.0",
         "1.375",
         "1.2",
         "2.1875",
         "11.0",
         "12.0",
         "17.0",
         "20.0",
         "2.0",
         "1.25",
         "1.1",
         "2.125",
         "10.0",
         "11.0",
         "17.0",
         "20.0",
         "2.5",
         "1.5",
         "1.1",
         "12.0",
         "11.0",
         "20.0"
        ],
        [
         "50%",
         "146.0",
         "21.0",
         "1.0",
         "1.0",
         "2.0",
         "2.0",
         "1.5",
         "2.75",
         "16.0",
         "15.0",
         "22.0",
         "2.86449",
         "3.23611",
         "3.333333333",
         "3.277777778",
         "21.0",
         "1.875",
         "1.5",
         "2.625",
         "15.0",
         "15.0",
         "21.0",
         "21.0",
         "2.0",
         "1.75",
         "1.4",
         "2.625",
         "14.0",
         "14.0",
         "21.0",
         "21.0",
         "3.125",
         "2.0",
         "1.4",
         "16.0",
         "14.0",
         "25.0"
        ],
        [
         "75%",
         "217.5",
         "22.0",
         "2.0",
         "1.0",
         "2.0",
         "3.0",
         "2.1",
         "3.375",
         "24.0",
         "21.0",
         "27.0",
         "3.36687",
         "3.6125",
         "3.7",
         "3.611111111",
         "22.5",
         "2.75",
         "2.0",
         "3.375",
         "22.0",
         "20.0",
         "27.0",
         "23.0",
         "2.0",
         "2.5625",
         "2.0",
         "3.14286",
         "20.5",
         "20.0",
         "25.0",
         "23.0",
         "3.6875",
         "3.0",
         "2.0",
         "24.0",
         "20.0",
         "29.5"
        ],
        [
         "max",
         "515.0",
         "44.0",
         "2.0",
         "5.0",
         "2.0",
         "5.0",
         "4.7",
         "5.0",
         "40.0",
         "47.0",
         "40.0",
         "4.60571",
         "4.73611",
         "4.8",
         "4.777777778",
         "44.0",
         "5.0",
         "4.6",
         "5.0",
         "40.0",
         "46.0",
         "40.0",
         "44.0",
         "2.0",
         "5.0",
         "4.5",
         "4.875",
         "39.0",
         "45.0",
         "39.0",
         "44.0",
         "4.875",
         "5.0",
         "4.6",
         "40.0",
         "46.0",
         "39.0"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age_T1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Edu_T1</th>\n",
       "      <th>MH_Diag_T1</th>\n",
       "      <th>MASQDG_mean_T1</th>\n",
       "      <th>MASQAN_mean_T1</th>\n",
       "      <th>MASQ_ANH_mean_T1</th>\n",
       "      <th>MASQDG_sum_T1</th>\n",
       "      <th>MASQAN_sum_T1</th>\n",
       "      <th>...</th>\n",
       "      <th>MASQDG_sum_T3</th>\n",
       "      <th>MASQAN_sum_T3</th>\n",
       "      <th>MASQ_ANH_sum_T3</th>\n",
       "      <th>Age_T4</th>\n",
       "      <th>MASQ_ANH_mean_T4</th>\n",
       "      <th>MASQDG_mean_T4</th>\n",
       "      <th>MASQAN_mean_T4</th>\n",
       "      <th>MASQDG_sum_T4</th>\n",
       "      <th>MASQAN_sum_T4</th>\n",
       "      <th>MASQ_ANH_sum_T4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>162.025974</td>\n",
       "      <td>21.943723</td>\n",
       "      <td>1.305677</td>\n",
       "      <td>1.350649</td>\n",
       "      <td>1.774892</td>\n",
       "      <td>2.274505</td>\n",
       "      <td>1.772872</td>\n",
       "      <td>2.800788</td>\n",
       "      <td>18.147186</td>\n",
       "      <td>17.653680</td>\n",
       "      <td>...</td>\n",
       "      <td>16.112554</td>\n",
       "      <td>16.536797</td>\n",
       "      <td>21.402597</td>\n",
       "      <td>22.480519</td>\n",
       "      <td>3.083473</td>\n",
       "      <td>2.294939</td>\n",
       "      <td>1.666522</td>\n",
       "      <td>18.259740</td>\n",
       "      <td>16.606061</td>\n",
       "      <td>24.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>113.908656</td>\n",
       "      <td>4.109516</td>\n",
       "      <td>0.461703</td>\n",
       "      <td>0.814535</td>\n",
       "      <td>0.418561</td>\n",
       "      <td>1.042252</td>\n",
       "      <td>0.831725</td>\n",
       "      <td>0.770622</td>\n",
       "      <td>8.324661</td>\n",
       "      <td>8.215652</td>\n",
       "      <td>...</td>\n",
       "      <td>7.667286</td>\n",
       "      <td>7.433016</td>\n",
       "      <td>5.838984</td>\n",
       "      <td>4.142916</td>\n",
       "      <td>0.774055</td>\n",
       "      <td>0.986329</td>\n",
       "      <td>0.731156</td>\n",
       "      <td>7.858093</td>\n",
       "      <td>7.318574</td>\n",
       "      <td>6.246716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>71.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>217.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>515.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Age_T1      Gender      Edu_T1  MH_Diag_T1  \\\n",
       "count  231.000000  231.000000  229.000000  231.000000  231.000000   \n",
       "mean   162.025974   21.943723    1.305677    1.350649    1.774892   \n",
       "std    113.908656    4.109516    0.461703    0.814535    0.418561   \n",
       "min      1.000000   17.000000    1.000000    1.000000    1.000000   \n",
       "25%     71.500000   20.000000    1.000000    1.000000    2.000000   \n",
       "50%    146.000000   21.000000    1.000000    1.000000    2.000000   \n",
       "75%    217.500000   22.000000    2.000000    1.000000    2.000000   \n",
       "max    515.000000   44.000000    2.000000    5.000000    2.000000   \n",
       "\n",
       "       MASQDG_mean_T1  MASQAN_mean_T1  MASQ_ANH_mean_T1  MASQDG_sum_T1  \\\n",
       "count      231.000000      231.000000        231.000000     231.000000   \n",
       "mean         2.274505        1.772872          2.800788      18.147186   \n",
       "std          1.042252        0.831725          0.770622       8.324661   \n",
       "min          1.000000        1.000000          1.000000       7.000000   \n",
       "25%          1.375000        1.100000          2.250000      11.000000   \n",
       "50%          2.000000        1.500000          2.750000      16.000000   \n",
       "75%          3.000000        2.100000          3.375000      24.000000   \n",
       "max          5.000000        4.700000          5.000000      40.000000   \n",
       "\n",
       "       MASQAN_sum_T1  ...  MASQDG_sum_T3  MASQAN_sum_T3  MASQ_ANH_sum_T3  \\\n",
       "count     231.000000  ...     231.000000     231.000000       231.000000   \n",
       "mean       17.653680  ...      16.112554      16.536797        21.402597   \n",
       "std         8.215652  ...       7.667286       7.433016         5.838984   \n",
       "min         9.000000  ...       7.000000       9.000000         8.000000   \n",
       "25%        11.000000  ...      10.000000      11.000000        17.000000   \n",
       "50%        15.000000  ...      14.000000      14.000000        21.000000   \n",
       "75%        21.000000  ...      20.500000      20.000000        25.000000   \n",
       "max        47.000000  ...      39.000000      45.000000        39.000000   \n",
       "\n",
       "           Age_T4  MASQ_ANH_mean_T4  MASQDG_mean_T4  MASQAN_mean_T4  \\\n",
       "count  231.000000        231.000000      231.000000      231.000000   \n",
       "mean    22.480519          3.083473        2.294939        1.666522   \n",
       "std      4.142916          0.774055        0.986329        0.731156   \n",
       "min     18.000000          1.125000        1.000000        1.000000   \n",
       "25%     20.000000          2.500000        1.500000        1.100000   \n",
       "50%     21.000000          3.125000        2.000000        1.400000   \n",
       "75%     23.000000          3.687500        3.000000        2.000000   \n",
       "max     44.000000          4.875000        5.000000        4.600000   \n",
       "\n",
       "       MASQDG_sum_T4  MASQAN_sum_T4  MASQ_ANH_sum_T4  \n",
       "count     231.000000     231.000000       231.000000  \n",
       "mean       18.259740      16.606061        24.610390  \n",
       "std         7.858093       7.318574         6.246716  \n",
       "min         7.000000       6.000000         9.000000  \n",
       "25%        12.000000      11.000000        20.000000  \n",
       "50%        16.000000      14.000000        25.000000  \n",
       "75%        24.000000      20.000000        29.500000  \n",
       "max        40.000000      46.000000        39.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e1de4",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "task 1:\n",
    "\n",
    "Analyze two variables:\n",
    "\n",
    "    1)Extra_T1\n",
    "    2)MASQAN_sum_T1\n",
    "\n",
    "Select appropriate tests to check if there is a difference in values of each variable in the following groups:\n",
    "\n",
    "    -People with and without mental health disorder diagnosis (MH_Diag_T1)\n",
    "    -Males and females (Gender)\n",
    "    -People of different age groups (Age_T1_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01cf05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: Extra_T1 по группировке: MH_Diag_T1_label ===\n",
      "\n",
      "1) Описательная статистика по группам (n, mean, median, sd, IQR):\n",
      "\n",
      "                              n      mean    median        sd        Q1        Q3       IQR\n",
      "MH_Diag_T1_label                                                                           \n",
      "Mental_health_diagnosis      52  3.042697  3.091665  0.674209  2.580553  3.528525  0.947973\n",
      "No_mental_health_diagnosis  179  3.298335  3.291670  0.461639  2.968055  3.629665  0.661610\n",
      "\n",
      "(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\n",
      "\n",
      "2) Тест нормальности (Shapiro-Wilk) по группам:\n",
      "   Группа Mental_health_diagnosis: n=52, W=0.9673, p=0.1615 -> Нормальность не отвергается\n",
      "   Группа No_mental_health_diagnosis: n=179, W=0.9904, p=0.2720 -> Нормальность не отвергается\n",
      "\n",
      "(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\n",
      "\n",
      "3) Levene (гомогенность дисперсий): stat=11.2643, p=0.0009 -> Дисперсии НЕ однородны (используйте Welch t-test или непараметрический тест)\n",
      "\n",
      "(Примечание: Levene с center='median' более устойчив к выбросам.)\n",
      "\n",
      "4) Выбор теста на основе проверок предпосылок:\n",
      "   Оба распределения похожи на нормальные -> используем t-test. Independent t-test (Welch if equal_var=False): equal_var=False\n",
      "   t = -2.5651, p = 0.012613\n",
      "   Разница средних (mean(Mental_health_diagnosis) - mean(No_mental_health_diagnosis)) = -0.2556\n",
      "   95% CI для разницы средних ≈ [-0.4546, -0.0566] (df≈65.5)\n",
      "   Cohen's d = -0.495 -> малый эффект\n",
      "\n",
      "5) Итоговая интерпретация (руководство по чтению результата):\n",
      "   p = 0.012613 < 0.05 -> отвергаем H0. Есть статистически значимая разница между группами.\n",
      "   По средним: mean(Mental_health_diagnosis) = 3.043, mean(No_mental_health_diagnosis) = 3.298. Значение Extra_T1 выше в группе No_mental_health_diagnosis.\n",
      "   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\n"
     ]
    }
   ],
   "source": [
    "# 1.1 анализ для Extra_T1 и People with and without mental health disorder diagnosis (MH_Diag_T1)\n",
    "\n",
    "# Читаемые метки\n",
    "df['MH_Diag_T1_label'] = df['MH_Diag_T1'].map({1: 'Mental_health_diagnosis', 2: 'No_mental_health_diagnosis'})\n",
    "\n",
    "var = 'Extra_T1'\n",
    "group_col = 'MH_Diag_T1_label'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по группам (n, mean, median, sd, IQR):\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Тест нормальности (Shapiro-Wilk) для каждой группы\n",
    "print(\"2) Тест нормальности (Shapiro-Wilk) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   Группа {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \n",
    "              \"Нормальность не отвергается\" if p>alpha else \"Нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   Группа {g}: n={len(vals)} < 3 — Shapiro не проводится\")\n",
    "\n",
    "print(\"\\n(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\\n\")\n",
    "\n",
    "# 3) Тест однородности дисперсий (Levene)\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene (гомогенность дисперсий): stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \n",
    "          \"Дисперсии однородны (можно t-test с equal_var=True)\" if lev_p>alpha else \"Дисперсии НЕ однородны (используйте Welch t-test или непараметрический тест)\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "print(\"\\n(Примечание: Levene с center='median' более устойчив к выбросам.)\\n\")\n",
    "\n",
    "# 4) Выбор теста (две независимые группы)\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "if len(groups) != 2:\n",
    "    raise ValueError(\"Ожидалось ровно 2 группы в столбце \" + group_col)\n",
    "g1, g2 = groups[0], groups[1]\n",
    "vals1 = data.loc[data[group_col]==g1, var].values\n",
    "vals2 = data.loc[data[group_col]==g2, var].values\n",
    "\n",
    "normal1 = (not np.isnan(shapiro_p[g1])) and (shapiro_p[g1] > alpha)\n",
    "normal2 = (not np.isnan(shapiro_p[g2])) and (shapiro_p[g2] > alpha)\n",
    "\n",
    "print(\"4) Выбор теста на основе проверок предпосылок:\")\n",
    "if normal1 and normal2:\n",
    "    # параметрический путь\n",
    "    equal_var = (not np.isnan(lev_p)) and (lev_p > alpha)\n",
    "    tstat, pval = stats.ttest_ind(vals1, vals2, equal_var=equal_var)\n",
    "    test_used = f\"Independent t-test (Welch if equal_var=False): equal_var={equal_var}\"\n",
    "    # Cohen's d (pooled SD)\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    s1, s2 = np.std(vals1, ddof=1), np.std(vals2, ddof=1)\n",
    "    pooled_sd = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1 + n2 - 2)) if (n1 + n2 - 2)>0 else np.nan\n",
    "    cohen_d = (np.mean(vals1) - np.mean(vals2)) / pooled_sd if pooled_sd>0 else np.nan\n",
    "    # 95% CI для разницы средних (используем Welch df при unequal var)\n",
    "    mean_diff = np.mean(vals1) - np.mean(vals2)\n",
    "    se_diff = np.sqrt(s1**2/n1 + s2**2/n2)\n",
    "    # Welch-Satterthwaite df\n",
    "    num = (s1**2/n1 + s2**2/n2)**2\n",
    "    den = (s1**4)/((n1**2)*(n1-1)) + (s2**4)/((n2**2)*(n2-1))\n",
    "    df_welch = num/den if den>0 else (n1 + n2 - 2)\n",
    "    tcrit = stats.t.ppf(1 - alpha/2, df_welch)\n",
    "    ci_low = mean_diff - tcrit * se_diff\n",
    "    ci_high = mean_diff + tcrit * se_diff\n",
    "    print(f\"   Оба распределения похожи на нормальные -> используем t-test. {test_used}\")\n",
    "    print(f\"   t = {tstat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Разница средних (mean({g1}) - mean({g2})) = {mean_diff:.4f}\")\n",
    "    print(f\"   95% CI для разницы средних ≈ [{ci_low:.4f}, {ci_high:.4f}] (df≈{df_welch:.1f})\")\n",
    "    print(f\"   Cohen's d = {cohen_d:.3f} ->\", end=\" \")\n",
    "    if abs(cohen_d) < 0.2:\n",
    "        print(\"очень маленький/незначительный эффект\")\n",
    "    elif abs(cohen_d) < 0.5:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(cohen_d) < 0.8:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "else:\n",
    "    # непараметрический путь\n",
    "    ustat, pval = stats.mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    test_used = \"Mann-Whitney U (непараметрический)\"\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    mean_u = n1 * n2 / 2\n",
    "    sd_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    z = (ustat - mean_u) / sd_u if sd_u>0 else 0\n",
    "    r = z / np.sqrt(n1 + n2)\n",
    "    med_diff = np.median(vals1) - np.median(vals2)\n",
    "    print(f\"   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\")\n",
    "    print(f\"   U = {ustat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Медианная разница (median({g1}) - median({g2})) = {med_diff:.4f}\")\n",
    "    print(f\"   Приближение эффекта: rank-biserial (r) ≈ {abs(r):.3f} ->\", end=\" \")\n",
    "    if abs(r) < 0.1:\n",
    "        print(\"очень маленький эффект\")\n",
    "    elif abs(r) < 0.3:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(r) < 0.5:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "\n",
    "# 5) Итоговая интерпретация решения\n",
    "print(\"\\n5) Итоговая интерпретация (руководство по чтению результата):\")\n",
    "if pval < alpha:\n",
    "    # определить направление: по средним и медианам\n",
    "    mean1, mean2 = np.mean(vals1), np.mean(vals2)\n",
    "    med1, med2 = np.median(vals1), np.median(vals2)\n",
    "    direction = f\"Значение {var} выше в группе {g1}\" if mean1 > mean2 else f\"Значение {var} выше в группе {g2}\"\n",
    "    print(f\"   p = {pval:.6f} < {alpha} -> отвергаем H0. Есть статистически значимая разница между группами.\")\n",
    "    print(f\"   По средним: mean({g1}) = {mean1:.3f}, mean({g2}) = {mean2:.3f}. {direction}.\")\n",
    "    print(\"   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\")\n",
    "else:\n",
    "    print(f\"   p = {pval:.6f} >= {alpha} -> нет достаточно доказательств, чтобы утверждать про различие между группами.\")\n",
    "    print(\"   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c5c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: MASQAN_sum_T1 по группировке: MH_Diag_T1_label ===\n",
      "\n",
      "1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\n",
      "\n",
      "                              n       mean  median        sd    Q1    Q3   IQR\n",
      "MH_Diag_T1_label                                                              \n",
      "Mental_health_diagnosis      52  22.538462    19.0  10.02636  14.0  31.0  17.0\n",
      "No_mental_health_diagnosis  179  16.234637    14.0   7.02969  11.0  18.0   7.0\n",
      "\n",
      "(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\n",
      "\n",
      "2) Тест нормальности (Shapiro-Wilk) по группам:\n",
      "   Группа Mental_health_diagnosis: n=52, W=0.9131, p=0.0011 -> Нормальность отвергается\n",
      "   Группа No_mental_health_diagnosis: n=179, W=0.8178, p=0.0000 -> Нормальность отвергается\n",
      "\n",
      "(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\n",
      "\n",
      "3) Levene (гомогенность дисперсий): stat=17.3253, p=0.0000 -> Дисперсии НЕ однородны\n",
      "\n",
      "(Примечание: Levene с center='median' более устойчив к выбросам.)\n",
      "\n",
      "4) Выбор теста на основе проверок предпосылок:\n",
      "   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\n",
      "   U = 6481.0000, p = 0.000015\n",
      "   Медианная разница (median(Mental_health_diagnosis) - median(No_mental_health_diagnosis)) = 5.0000\n",
      "   Приближение эффекта: rank-biserial (r) ≈ 0.283 -> малый эффект\n",
      "\n",
      "5) Итоговая интерпретация (руководство по чтению результата):\n",
      "   p = 0.000015 < 0.05 -> отвергаем H0. Есть статистически значимая разница между группами.\n",
      "   По средним: mean(Mental_health_diagnosis) = 22.538, mean(No_mental_health_diagnosis) = 16.235. Значение MASQAN_sum_T1 выше в группе Mental_health_diagnosis.\n",
      "   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 анализ для MASQAN_sum_T1 и People with and without mental health disorder diagnosis (MH_Diag_T1)\n",
    "\n",
    "\n",
    "\n",
    "# Метки для читаемости\n",
    "df['MH_Diag_T1_label'] = df['MH_Diag_T1'].map({1: 'Mental_health_diagnosis', 2: 'No_mental_health_diagnosis'})\n",
    "\n",
    "var = 'MASQAN_sum_T1'\n",
    "group_col = 'MH_Diag_T1_label'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Shapiro-Wilk нормальности по группам\n",
    "print(\"2) Тест нормальности (Shapiro-Wilk) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   Группа {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \n",
    "              \"Нормальность не отвергается\" if p>alpha else \"Нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   Группа {g}: n={len(vals)} < 3 — Shapiro не проводится\")\n",
    "\n",
    "print(\"\\n(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\\n\")\n",
    "\n",
    "# 3) Levene для гомогенности дисперсий\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene (гомогенность дисперсий): stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \n",
    "          \"Дисперсии однородны\" if lev_p>alpha else \"Дисперсии НЕ однородны\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "print(\"\\n(Примечание: Levene с center='median' более устойчив к выбросам.)\\n\")\n",
    "\n",
    "# 4) Выбор теста и расчёт эффекта\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "if len(groups) != 2:\n",
    "    raise ValueError(\"Ожидалось ровно 2 группы в столбце \" + group_col)\n",
    "g1, g2 = groups[0], groups[1]\n",
    "vals1 = data.loc[data[group_col]==g1, var].values\n",
    "vals2 = data.loc[data[group_col]==g2, var].values\n",
    "\n",
    "normal1 = (not np.isnan(shapiro_p[g1])) and (shapiro_p[g1] > alpha)\n",
    "normal2 = (not np.isnan(shapiro_p[g2])) and (shapiro_p[g2] > alpha)\n",
    "\n",
    "print(\"4) Выбор теста на основе проверок предпосылок:\")\n",
    "if normal1 and normal2:\n",
    "    equal_var = (not np.isnan(lev_p)) and (lev_p > alpha)\n",
    "    tstat, pval = stats.ttest_ind(vals1, vals2, equal_var=equal_var)\n",
    "    test_used = f\"Independent t-test (Welch if equal_var=False): equal_var={equal_var}\"\n",
    "    # Cohen's d\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    s1, s2 = np.std(vals1, ddof=1), np.std(vals2, ddof=1)\n",
    "    pooled_sd = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1 + n2 - 2)) if (n1 + n2 - 2)>0 else np.nan\n",
    "    cohen_d = (np.mean(vals1) - np.mean(vals2)) / pooled_sd if pooled_sd>0 else np.nan\n",
    "    # CI for diff of means (Welch df if needed)\n",
    "    mean_diff = np.mean(vals1) - np.mean(vals2)\n",
    "    se_diff = np.sqrt(s1**2/n1 + s2**2/n2)\n",
    "    num = (s1**2/n1 + s2**2/n2)**2\n",
    "    den = (s1**4)/((n1**2)*(n1-1)) + (s2**4)/((n2**2)*(n2-1))\n",
    "    df_welch = num/den if den>0 else (n1 + n2 - 2)\n",
    "    tcrit = stats.t.ppf(1 - alpha/2, df_welch)\n",
    "    ci_low = mean_diff - tcrit * se_diff\n",
    "    ci_high = mean_diff + tcrit * se_diff\n",
    "    print(f\"   Оба распределения похожи на нормальные -> используем t-test. {test_used}\")\n",
    "    print(f\"   t = {tstat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Разница средних (mean({g1}) - mean({g2})) = {mean_diff:.4f}\")\n",
    "    print(f\"   95% CI для разницы средних ≈ [{ci_low:.4f}, {ci_high:.4f}] (df≈{df_welch:.1f})\")\n",
    "    print(f\"   Cohen's d = {cohen_d:.3f} ->\", end=\" \")\n",
    "    if abs(cohen_d) < 0.2:\n",
    "        print(\"очень маленький/незначительный эффект\")\n",
    "    elif abs(cohen_d) < 0.5:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(cohen_d) < 0.8:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "else:\n",
    "    ustat, pval = stats.mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    test_used = \"Mann-Whitney U (непараметрический)\"\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    mean_u = n1 * n2 / 2\n",
    "    sd_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    z = (ustat - mean_u) / sd_u if sd_u>0 else 0\n",
    "    r = z / np.sqrt(n1 + n2)\n",
    "    med_diff = np.median(vals1) - np.median(vals2)\n",
    "    print(f\"   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\")\n",
    "    print(f\"   U = {ustat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Медианная разница (median({g1}) - median({g2})) = {med_diff:.4f}\")\n",
    "    print(f\"   Приближение эффекта: rank-biserial (r) ≈ {abs(r):.3f} ->\", end=\" \")\n",
    "    if abs(r) < 0.1:\n",
    "        print(\"очень маленький эффект\")\n",
    "    elif abs(r) < 0.3:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(r) < 0.5:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "\n",
    "# 5) Итоговая интерпретация\n",
    "print(\"\\n5) Итоговая интерпретация (руководство по чтению результата):\")\n",
    "if pval < alpha:\n",
    "    mean1, mean2 = np.mean(vals1), np.mean(vals2)\n",
    "    med1, med2 = np.median(vals1), np.median(vals2)\n",
    "    direction = f\"Значение {var} выше в группе {g1}\" if mean1 > mean2 else f\"Значение {var} выше в группе {g2}\"\n",
    "    print(f\"   p = {pval:.6f} < {alpha} -> отвергаем H0. Есть статистически значимая разница между группами.\")\n",
    "    print(f\"   По средним: mean({g1}) = {mean1:.3f}, mean({g2}) = {mean2:.3f}. {direction}.\")\n",
    "    print(\"   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\")\n",
    "else:\n",
    "    print(f\"   p = {pval:.6f} >= {alpha} -> нет достаточно доказательств, чтобы утверждать про различие между группами.\")\n",
    "    print(\"   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f023e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: Extra_T1 по группировке: Gender_label ===\n",
      "\n",
      "1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\n",
      "\n",
      "                n      mean    median        sd       Q1        Q3       IQR\n",
      "Gender_label                                                                \n",
      "Female        159  3.215908  3.192670  0.525843  2.93939  3.579665  0.640275\n",
      "Male           70  3.284541  3.341665  0.530495  2.95278  3.618113  0.665332\n",
      "\n",
      "(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\n",
      "\n",
      "2) Тест нормальности (Shapiro-Wilk) по группам:\n",
      "   Группа Female: n=159, W=0.9895, p=0.2822 -> Нормальность не отвергается\n",
      "   Группа Male: n=70, W=0.9796, p=0.3100 -> Нормальность не отвергается\n",
      "\n",
      "(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\n",
      "\n",
      "3) Levene (гомогенность дисперсий): stat=0.0000, p=0.9965 -> Дисперсии однородны\n",
      "\n",
      "(Примечание: Levene с center='median' более устойчив к выбросам.)\n",
      "\n",
      "4) Выбор теста на основе проверок предпосылок:\n",
      "   Оба распределения похожи на нормальные -> используем t-test. Independent t-test (Welch if equal_var=False): equal_var=True\n",
      "   t = -0.9075, p = 0.365114\n",
      "   Разница средних (mean(Female) - mean(Male)) = -0.0686\n",
      "   95% CI для разницы средних ≈ [-0.2188, 0.0815] (df≈130.9)\n",
      "   Cohen's d = -0.130 -> очень маленький/незначительный эффект\n",
      "\n",
      "5) Итоговая интерпретация (руководство по чтению результата):\n",
      "   p = 0.365114 >= 0.05 -> нет достаточно доказательств, чтобы утверждать про различие между группами.\n",
      "   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\n"
     ]
    }
   ],
   "source": [
    "# 1.2 анализ для Extra_T1 и Males and females (Gender)\n",
    "\n",
    "\n",
    "# Маппинг пола (1-Female, 2-Male)\n",
    "df['Gender_label'] = df['Gender'].map({1: 'Female', 2: 'Male'})\n",
    "\n",
    "var = 'Extra_T1'\n",
    "group_col = 'Gender_label'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Shapiro-Wilk нормальности по группам\n",
    "print(\"2) Тест нормальности (Shapiro-Wilk) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   Группа {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \n",
    "              \"Нормальность не отвергается\" if p>alpha else \"Нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   Группа {g}: n={len(vals)} < 3 — Shapiro не проводится\")\n",
    "\n",
    "print(\"\\n(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\\n\")\n",
    "\n",
    "# 3) Levene для гомогенности дисперсий\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene (гомогенность дисперсий): stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \n",
    "          \"Дисперсии однородны\" if lev_p>alpha else \"Дисперсии НЕ однородны\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "print(\"\\n(Примечание: Levene с center='median' более устойчив к выбросам.)\\n\")\n",
    "\n",
    "# 4) Выбор теста и расчёт эффекта\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "if len(groups) != 2:\n",
    "    raise ValueError(\"Ожидалось ровно 2 группы в столбце \" + group_col)\n",
    "g1, g2 = groups[0], groups[1]  # alphabetical: Female, Male\n",
    "vals1 = data.loc[data[group_col]==g1, var].values\n",
    "vals2 = data.loc[data[group_col]==g2, var].values\n",
    "\n",
    "normal1 = (not np.isnan(shapiro_p[g1])) and (shapiro_p[g1] > alpha)\n",
    "normal2 = (not np.isnan(shapiro_p[g2])) and (shapiro_p[g2] > alpha)\n",
    "\n",
    "print(\"4) Выбор теста на основе проверок предпосылок:\")\n",
    "if normal1 and normal2:\n",
    "    equal_var = (not np.isnan(lev_p)) and (lev_p > alpha)\n",
    "    tstat, pval = stats.ttest_ind(vals1, vals2, equal_var=equal_var)\n",
    "    test_used = f\"Independent t-test (Welch if equal_var=False): equal_var={equal_var}\"\n",
    "    # Cohen's d\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    s1, s2 = np.std(vals1, ddof=1), np.std(vals2, ddof=1)\n",
    "    pooled_sd = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1 + n2 - 2)) if (n1 + n2 - 2)>0 else np.nan\n",
    "    cohen_d = (np.mean(vals1) - np.mean(vals2)) / pooled_sd if pooled_sd>0 else np.nan\n",
    "    # CI for diff of means (Welch df if needed)\n",
    "    mean_diff = np.mean(vals1) - np.mean(vals2)\n",
    "    se_diff = np.sqrt(s1**2/n1 + s2**2/n2)\n",
    "    num = (s1**2/n1 + s2**2/n2)**2\n",
    "    den = (s1**4)/((n1**2)*(n1-1)) + (s2**4)/((n2**2)*(n2-1))\n",
    "    df_welch = num/den if den>0 else (n1 + n2 - 2)\n",
    "    tcrit = stats.t.ppf(1 - alpha/2, df_welch)\n",
    "    ci_low = mean_diff - tcrit * se_diff\n",
    "    ci_high = mean_diff + tcrit * se_diff\n",
    "    print(f\"   Оба распределения похожи на нормальные -> используем t-test. {test_used}\")\n",
    "    print(f\"   t = {tstat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Разница средних (mean({g1}) - mean({g2})) = {mean_diff:.4f}\")\n",
    "    print(f\"   95% CI для разницы средних ≈ [{ci_low:.4f}, {ci_high:.4f}] (df≈{df_welch:.1f})\")\n",
    "    print(f\"   Cohen's d = {cohen_d:.3f} ->\", end=\" \")\n",
    "    if abs(cohen_d) < 0.2:\n",
    "        print(\"очень маленький/незначительный эффект\")\n",
    "    elif abs(cohen_d) < 0.5:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(cohen_d) < 0.8:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "else:\n",
    "    ustat, pval = stats.mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    test_used = \"Mann-Whitney U (непараметрический)\"\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    mean_u = n1 * n2 / 2\n",
    "    sd_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    z = (ustat - mean_u) / sd_u if sd_u>0 else 0\n",
    "    r = z / np.sqrt(n1 + n2)\n",
    "    med_diff = np.median(vals1) - np.median(vals2)\n",
    "    print(f\"   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\")\n",
    "    print(f\"   U = {ustat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Медианная разница (median({g1}) - median({g2})) = {med_diff:.4f}\")\n",
    "    print(f\"   Приближение эффекта: rank-biserial (r) ≈ {abs(r):.3f} ->\", end=\" \")\n",
    "    if abs(r) < 0.1:\n",
    "        print(\"очень маленький эффект\")\n",
    "    elif abs(r) < 0.3:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(r) < 0.5:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "\n",
    "# 5) Итоговая интерпретация\n",
    "print(\"\\n5) Итоговая интерпретация (руководство по чтению результата):\")\n",
    "if pval < alpha:\n",
    "    mean1, mean2 = np.mean(vals1), np.mean(vals2)\n",
    "    med1, med2 = np.median(vals1), np.median(vals2)\n",
    "    direction = f\"Значение {var} выше в группе {g1}\" if mean1 > mean2 else f\"Значение {var} выше в группе {g2}\"\n",
    "    print(f\"   p = {pval:.6f} < {alpha} -> отвергаем H0. Есть статистически значимая разница между группами.\")\n",
    "    print(f\"   По средним: mean({g1}) = {mean1:.3f}, mean({g2}) = {mean2:.3f}. {direction}.\")\n",
    "    print(\"   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\")\n",
    "else:\n",
    "    print(f\"   p = {pval:.6f} >= {alpha} -> нет достаточно доказательств, чтобы утверждать про различие между группами.\")\n",
    "    print(\"   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5794f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: MASQAN_sum_T1 по группировке: Gender_label ===\n",
      "\n",
      "1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\n",
      "\n",
      "                n       mean  median        sd    Q1    Q3   IQR\n",
      "Gender_label                                                    \n",
      "Female        159  18.069182    15.0  8.267000  12.0  22.5  10.5\n",
      "Male           70  16.428571    14.0  7.474733  11.0  19.0   8.0\n",
      "\n",
      "(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\n",
      "\n",
      "2) Тест нормальности (Shapiro-Wilk) по группам:\n",
      "   Группа Female: n=159, W=0.8441, p=0.0000 -> Нормальность отвергается\n",
      "   Группа Male: n=70, W=0.8075, p=0.0000 -> Нормальность отвергается\n",
      "\n",
      "(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\n",
      "\n",
      "3) Levene (гомогенность дисперсий): stat=0.8428, p=0.3596 -> Дисперсии однородны\n",
      "\n",
      "(Примечание: Levene с center='median' более устойчив к выбросам.)\n",
      "\n",
      "4) Выбор теста на основе проверок предпосылок:\n",
      "   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\n",
      "   U = 6243.5000, p = 0.140631\n",
      "   Медианная разница (median(Female) - median(Male)) = 1.0000\n",
      "   Приближение эффекта: rank-biserial (r) ≈ 0.097 -> очень маленький эффект\n",
      "\n",
      "5) Итоговая интерпретация (руководство по чтению результата):\n",
      "   p = 0.140631 >= 0.05 -> нет достаточно доказательств, чтобы утверждать про различие между группами.\n",
      "   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\n"
     ]
    }
   ],
   "source": [
    "# 2.2 анализ для MASQAN_sum_T1 и Males and females (Gender)\n",
    "\n",
    "\n",
    "df['Gender_label'] = df['Gender'].map({1: 'Female', 2: 'Male'})\n",
    "\n",
    "var = 'MASQAN_sum_T1'\n",
    "group_col = 'Gender_label'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по группам (n, mean, median, sd, Q1, Q3, IQR):\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Примечание: смотрим на n — маленькие n снижают надёжность тестов; IQR и медиана полезны при нарушении нормальности.)\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Shapiro-Wilk нормальности по группам\n",
    "print(\"2) Тест нормальности (Shapiro-Wilk) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   Группа {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \n",
    "              \"Нормальность не отвергается\" if p>alpha else \"Нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   Группа {g}: n={len(vals)} < 3 — Shapiro не проводится\")\n",
    "\n",
    "print(\"\\n(Интерпретация: если обе группы не отвергают нормальность, можно рассмотреть параметрические тесты; иначе — непараметрические.)\\n\")\n",
    "\n",
    "# 3) Levene для гомогенности дисперсий\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene (гомогенность дисперсий): stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \n",
    "          \"Дисперсии однородны\" if lev_p>alpha else \"Дисперсии НЕ однородны\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "print(\"\\n(Примечание: Levene с center='median' более устойчив к выбросам.)\\n\")\n",
    "\n",
    "# 4) Выбор теста и расчёт эффекта\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "if len(groups) != 2:\n",
    "    raise ValueError(\"Ожидалось ровно 2 группы в столбце \" + group_col)\n",
    "g1, g2 = groups[0], groups[1]  # Female, Male\n",
    "vals1 = data.loc[data[group_col]==g1, var].values\n",
    "vals2 = data.loc[data[group_col]==g2, var].values\n",
    "\n",
    "normal1 = (not np.isnan(shapiro_p[g1])) and (shapiro_p[g1] > alpha)\n",
    "normal2 = (not np.isnan(shapiro_p[g2])) and (shapiro_p[g2] > alpha)\n",
    "\n",
    "print(\"4) Выбор теста на основе проверок предпосылок:\")\n",
    "if normal1 and normal2:\n",
    "    equal_var = (not np.isnan(lev_p)) and (lev_p > alpha)\n",
    "    tstat, pval = stats.ttest_ind(vals1, vals2, equal_var=equal_var)\n",
    "    test_used = f\"Independent t-test (Welch if equal_var=False): equal_var={equal_var}\"\n",
    "    # Cohen's d\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    s1, s2 = np.std(vals1, ddof=1), np.std(vals2, ddof=1)\n",
    "    pooled_sd = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1 + n2 - 2)) if (n1 + n2 - 2)>0 else np.nan\n",
    "    cohen_d = (np.mean(vals1) - np.mean(vals2)) / pooled_sd if pooled_sd>0 else np.nan\n",
    "    # CI for diff of means (Welch df if needed)\n",
    "    mean_diff = np.mean(vals1) - np.mean(vals2)\n",
    "    se_diff = np.sqrt(s1**2/n1 + s2**2/n2)\n",
    "    num = (s1**2/n1 + s2**2/n2)**2\n",
    "    den = (s1**4)/((n1**2)*(n1-1)) + (s2**4)/((n2**2)*(n2-1))\n",
    "    df_welch = num/den if den>0 else (n1 + n2 - 2)\n",
    "    tcrit = stats.t.ppf(1 - alpha/2, df_welch)\n",
    "    ci_low = mean_diff - tcrit * se_diff\n",
    "    ci_high = mean_diff + tcrit * se_diff\n",
    "    print(f\"   Оба распределения похожи на нормальные -> используем t-test. {test_used}\")\n",
    "    print(f\"   t = {tstat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Разница средних (mean({g1}) - mean({g2})) = {mean_diff:.4f}\")\n",
    "    print(f\"   95% CI для разницы средних ≈ [{ci_low:.4f}, {ci_high:.4f}] (df≈{df_welch:.1f})\")\n",
    "    print(f\"   Cohen's d = {cohen_d:.3f} ->\", end=\" \")\n",
    "    if abs(cohen_d) < 0.2:\n",
    "        print(\"очень маленький/незначительный эффект\")\n",
    "    elif abs(cohen_d) < 0.5:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(cohen_d) < 0.8:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "else:\n",
    "    ustat, pval = stats.mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    test_used = \"Mann-Whitney U (непараметрический)\"\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    mean_u = n1 * n2 / 2\n",
    "    sd_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    z = (ustat - mean_u) / sd_u if sd_u>0 else 0\n",
    "    r = z / np.sqrt(n1 + n2)\n",
    "    med_diff = np.median(vals1) - np.median(vals2)\n",
    "    print(f\"   По крайней мере в одной группе нормальность не выполняется -> используем Mann-Whitney.\")\n",
    "    print(f\"   U = {ustat:.4f}, p = {pval:.6f}\")\n",
    "    print(f\"   Медианная разница (median({g1}) - median({g2})) = {med_diff:.4f}\")\n",
    "    print(f\"   Приближение эффекта: rank-biserial (r) ≈ {abs(r):.3f} ->\", end=\" \")\n",
    "    if abs(r) < 0.1:\n",
    "        print(\"очень маленький эффект\")\n",
    "    elif abs(r) < 0.3:\n",
    "        print(\"малый эффект\")\n",
    "    elif abs(r) < 0.5:\n",
    "        print(\"умеренный эффект\")\n",
    "    else:\n",
    "        print(\"большой эффект\")\n",
    "\n",
    "# 5) Итоговая интерпретация\n",
    "print(\"\\n5) Итоговая интерпретация (руководство по чтению результата):\")\n",
    "if pval < alpha:\n",
    "    mean1, mean2 = np.mean(vals1), np.mean(vals2)\n",
    "    med1, med2 = np.median(vals1), np.median(vals2)\n",
    "    direction = f\"Значение {var} выше в группе {g1}\" if mean1 > mean2 else f\"Значение {var} выше в группе {g2}\"\n",
    "    print(f\"   p = {pval:.6f} < {alpha} -> отвергаем H0. Есть статистически значимая разница между группами.\")\n",
    "    print(f\"   По средним: mean({g1}) = {mean1:.3f}, mean({g2}) = {mean2:.3f}. {direction}.\")\n",
    "    print(\"   Проверьте размер эффекта (см. выше): p-value сообщает о статистической значимости, эффект показывает практическую значимость.\")\n",
    "else:\n",
    "    print(f\"   p = {pval:.6f} >= {alpha} -> нет достаточно доказательств, чтобы утверждать про различие между группами.\")\n",
    "    print(\"   Это НЕ доказывает равенство групп, а показывает отсутствие статистически значимой разницы при текущих данных и выбранной мощности теста.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "256527f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: Extra_T1 по группировке: Age_T1_group ===\n",
      "\n",
      "1) Описательная статистика по возрастным группам:\n",
      "\n",
      "               n      mean    median        sd       Q1        Q3       IQR\n",
      "Age_T1_group                                                               \n",
      "17-20         97  3.179234  3.200000  0.531204  2.92322  3.500000  0.576780\n",
      "21-22         78  3.325723  3.361610  0.500600  3.01692  3.665525  0.648605\n",
      ">23           56  3.229109  3.193055  0.546496  2.92317  3.589583  0.666413\n",
      "\n",
      "(Примечание: проверьте размеры групп и распределения перед выбором теста.)\n",
      "\n",
      "2) Shapiro-Wilk (нормальность) по группам:\n",
      "   17-20: n=97, W=0.9676, p=0.0169 -> нормальность отвергается\n",
      "   21-22: n=78, W=0.9847, p=0.4730 -> нормальность не отвергается\n",
      "   >23: n=56, W=0.9860, p=0.7587 -> нормальность не отвергается\n",
      "\n",
      "(Если хотя бы одна группа не нормальна, предпочтителен непараметрический тест.)\n",
      "\n",
      "3) Levene: stat=0.0528, p=0.9486 -> дисперсии однородны\n",
      "\n",
      "4) Выбор теста и выполнение:\n",
      "   Применён Kruskal-Wallis: H = 2.3743, p = 0.305088\n",
      "   ε² (epsilon-squared) ≈ 0.002 (оценка размера эффекта)\n",
      "\n",
      "5) Пост-hoc не выполняется, т.к. общий тест не значим (p >= 0.05). pval=0.3050876219334467\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Extra_T1 и People of different age groups (Age_T1_group)\n",
    "\n",
    "\n",
    "# Убедимся, что Age_T1_group имеет читаемые метки\n",
    "df['Age_T1_group'] = df['Age_T1_group'].astype(str)\n",
    "\n",
    "var = 'Extra_T1'\n",
    "group_col = 'Age_T1_group'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по возрастным группам:\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Примечание: проверьте размеры групп и распределения перед выбором теста.)\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Shapiro по группам\n",
    "print(\"2) Shapiro-Wilk (нормальность) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \"нормальность не отвергается\" if p>alpha else \"нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   {g}: n={len(vals)} <3 — Shapiro не проводится\")\n",
    "\n",
    "print(\"\\n(Если хотя бы одна группа не нормальна, предпочтителен непараметрический тест.)\\n\")\n",
    "\n",
    "# 3) Levene для гомогенности дисперсий\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene: stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \"дисперсии однородны\" if lev_p>alpha else \"дисперсии НЕ однородны\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "print(\"\\n4) Выбор теста и выполнение:\")\n",
    "# Решаем: если все группы нормальны и Levene p>alpha -> ANOVA, иначе Kruskal\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "group_vals = [data.loc[data[group_col]==g, var].values for g in groups]\n",
    "all_normal = all([(not np.isnan(shapiro_p[g])) and (shapiro_p[g] > alpha) for g in groups])\n",
    "if all_normal and (not np.isnan(lev_p)) and (lev_p > alpha):\n",
    "    # ANOVA\n",
    "    fstat, pval = stats.f_oneway(*group_vals)\n",
    "    print(f\"   Применён One-way ANOVA: F = {fstat:.4f}, p = {pval:.6f}\")\n",
    "    test_used = 'ANOVA'\n",
    "    # eta squared\n",
    "    # Compute total SS and between SS for eta^2\n",
    "    grand_mean = np.mean(data[var].values)\n",
    "    ss_between = sum([len(vals)*(np.mean(vals)-grand_mean)**2 for vals in group_vals])\n",
    "    ss_total = sum((data[var].values - grand_mean)**2)\n",
    "    eta2 = ss_between / ss_total if ss_total>0 else np.nan\n",
    "    print(f\"   η² (eta squared) ≈ {eta2:.3f}\")\n",
    "else:\n",
    "    # Kruskal-Wallis\n",
    "    hstat, pval = stats.kruskal(*group_vals)\n",
    "    print(f\"   Применён Kruskal-Wallis: H = {hstat:.4f}, p = {pval:.6f}\")\n",
    "    test_used = 'Kruskal-Wallis'\n",
    "    # epsilon-squared for effect size: (H - k + 1) / (n - k)\n",
    "    k = len(group_vals)\n",
    "    n = sum([len(v) for v in group_vals])\n",
    "    eps2 = (hstat - k + 1) / (n - k) if (n - k) > 0 else np.nan\n",
    "    print(f\"   ε² (epsilon-squared) ≈ {eps2:.3f} (оценка размера эффекта)\")\n",
    "\n",
    "# 5) Пост-hoc если значимо (используем парные Mann-Whitney + Bonferroni)\n",
    "if pval < alpha:\n",
    "    print(\"\\n5) Пост-hoc парные сравнения (Mann-Whitney) с Bonferroni коррекцией:\")\n",
    "    pairs = list(itertools.combinations(groups, 2))\n",
    "    m = len(pairs)\n",
    "    results = []\n",
    "    for (a,b) in pairs:\n",
    "        va = data.loc[data[group_col]==a, var].values\n",
    "        vb = data.loc[data[group_col]==b, var].values\n",
    "        ustat, up = stats.mannwhitneyu(va, vb, alternative='two-sided')\n",
    "        p_adj = min(up * m, 1.0)\n",
    "        # compute r effect approx\n",
    "        n1, n2 = len(va), len(vb)\n",
    "        mean_u = n1*n2/2\n",
    "        sd_u = math.sqrt(n1*n2*(n1+n2+1)/12)\n",
    "        z = (ustat - mean_u)/sd_u if sd_u>0 else 0\n",
    "        r = z / math.sqrt(n1 + n2)\n",
    "        results.append((a,b,ustat,up,p_adj,abs(r)))\n",
    "        print(f\"   {a} vs {b}: U={ustat:.2f}, p={up:.6f}, p_adj(Bonf)={p_adj:.6f}, approx r={abs(r):.3f}\")\n",
    "    print(f\"\\n(Интерпретация: посмотрите скорректированные p_adj; p_adj < 0.05 считается значимым.) pval={pval}\")\n",
    "else:\n",
    "    print(f\"\\n5) Пост-hoc не выполняется, т.к. общий тест не значим (p >= 0.05). pval={pval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7061a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Анализ переменной: MASQAN_sum_T1 по группировке: Age_T1_group ===\n",
      "\n",
      "1) Описательная статистика по возрастным группам:\n",
      "\n",
      "               n       mean  median        sd     Q1     Q3    IQR\n",
      "Age_T1_group                                                      \n",
      "17-20         97  18.577320    15.0  9.070138  12.00  24.00  12.00\n",
      "21-22         78  17.974359    16.0  7.236226  12.25  21.00   8.75\n",
      ">23           56  15.607143    13.0  7.709919  10.75  16.25   5.50\n",
      "\n",
      "(Обратите внимание на n и на IQR/median для непараметрического случая.)\n",
      "\n",
      ">> Вывод по описательной статистике:\n",
      "   Группа 17-20: n=97, mean=18.58, median=15.0, sd=9.07, IQR=12.00.\n",
      "   Группа 21-22: n=78, mean=17.97, median=16.0, sd=7.24, IQR=8.75.\n",
      "   Группа >23: n=56, mean=15.61, median=13.0, sd=7.71, IQR=5.50.\n",
      "   Интерпретация: сравните медианы и IQR — если медианы различаются и IQR невелик, различия могут быть устойчивыми; большие IQR указывают на большую изменчивость внутри группы.\n",
      "\n",
      "2) Shapiro-Wilk (нормальность) по группам:\n",
      "   17-20: n=97, W=0.8461, p=0.0000 -> нормальность отвергается\n",
      "   21-22: n=78, W=0.8841, p=0.0000 -> нормальность отвергается\n",
      "   >23: n=56, W=0.7116, p=0.0000 -> нормальность отвергается\n",
      "\n",
      ">> Вывод по проверке нормальности (Shapiro-Wilk):\n",
      "   В группе 17-20 распределение НЕ нормально (p=0.0000).\n",
      "   В группе 21-22 распределение НЕ нормально (p=0.0000).\n",
      "   В группе >23 распределение НЕ нормально (p=0.0000).\n",
      "   Интерпретация: поскольку хотя бы в одной группе нормальность нарушена, предпочтителен непараметрический тест (Kruskal-Wallis) для сравнения >2 групп.\n",
      "\n",
      "(Если сомневаетесь, визуализируйте распределения — гистограммы или Q-Q графики.)\n",
      "\n",
      "3) Levene (гомогенность дисперсий): stat=2.1807, p=0.1153 -> дисперсии однородны\n",
      "\n",
      ">> Вывод по Levene (гомогенность дисперсий):\n",
      "   Levene p=0.1153 > 0.05: дисперсии можно считать однородными — требование homoscedasticity выполнено.\n",
      "   Интерпретация: однородность дисперсий — одно из требований для применения ANOVA; отсутствие однородности уменьшает надёжность классической ANOVA.\n",
      "\n",
      "4) Выбор теста и выполнение:\n",
      "   Применён Kruskal-Wallis: H = 7.8341, p = 0.019900\n",
      "   ε² (epsilon-squared) ≈ 0.026 (оценка размера эффекта)\n",
      "\n",
      ">> Интерпретация результата Kruskal-Wallis:\n",
      "   H = 7.834, p = 0.0199 < 0.05: имеются статистически значимые различия между группами по MASQAN_sum_T1.\n",
      "   Дальше: проводить пост-hoc парные непараметрические тесты (Mann-Whitney или Dunn) с корректировкой множественных сравнений.\n",
      "   Интерпретация эффекта (ε²): чем ближе к 0 — тем слабее влияние групп, 0.01 ~ маленький, 0.06 ~ средний, 0.14 ~ большой (ориентировочно).\n",
      "\n",
      "\n",
      "5) Пост-hoc парные сравнения (Mann-Whitney) с Bonferroni коррекцией:\n",
      "   17-20 vs 21-22: U=3676.00, p=0.748496, p_adj(Bonf)=1.000000, median_diff=-1.00, approx r=0.024\n",
      "     -> p = 0.7485 >= 0.05: различие статистически незначимо (даже до коррекции).\n",
      "   17-20 vs >23: U=3311.00, p=0.023692, p_adj(Bonf)=0.071075, median_diff=2.00, approx r=0.182\n",
      "     -> До коррекции p = 0.0237 < 0.05, но после Bonferroni p_adj = 0.0711 >= 0.05 -> различие не выдержало строгой коррекции.\n",
      "        Интерпретация: возможно слабая/пограничная разница; можно рассмотреть менее консервативные поправки (Holm, BH).\n",
      "   21-22 vs >23: U=2790.00, p=0.006076, p_adj(Bonf)=0.018227, median_diff=3.00, approx r=0.236\n",
      "     -> После Bonferroni (p_adj=0.0182) разница значима. Медианная разница = 3.00. r≈0.236.\n",
      "        Интерпретация: статистически значимая разница между этими возрастными группами; оцените практическую значимость по r и по величине медианной разницы.\n",
      "\n",
      "(Интерпретация: смотрите p_adj; p_adj < 0.05 считается значимым. Обратите внимание на размер эффекта r и на разницу медиан.)\n",
      "\n",
      "=== Краткое итоговое заключение ===\n",
      "- Kruskal-Wallis H = 7.834, p = 0.0199 < 0.05: имеются различия между возрастными группами.\n",
      "  Размер эффекта ε² ≈ 0.026 (малый эффект). Рассмотрите post-hoc пары, оцените их практическую значимость.\n"
     ]
    }
   ],
   "source": [
    "# 2.3 MASQAN_sum_T1 и People of different age groups (Age_T1_group)\n",
    "\n",
    "df['Age_T1_group'] = df['Age_T1_group'].astype(str)\n",
    "\n",
    "var = 'MASQAN_sum_T1'\n",
    "group_col = 'Age_T1_group'\n",
    "data = df[[var, group_col]].dropna()\n",
    "\n",
    "print(\"=== Анализ переменной:\", var, \"по группировке:\", group_col, \"===\\n\")\n",
    "\n",
    "# 1) Описательная статистика\n",
    "desc = data.groupby(group_col)[var].agg(['count', 'mean', 'median', 'std', 'min', 'max', 'skew']).rename(columns={'count':'n','std':'sd'})\n",
    "iqr = data.groupby(group_col)[var].quantile([0.25, 0.75]).unstack(level=1).rename(columns={0.25:'Q1',0.75:'Q3'})\n",
    "desc = desc.join(iqr)\n",
    "desc['IQR'] = desc['Q3'] - desc['Q1']\n",
    "print(\"1) Описательная статистика по возрастным группам:\\n\")\n",
    "print(desc[['n','mean','median','sd','Q1','Q3','IQR']].to_string())\n",
    "print(\"\\n(Обратите внимание на n и на IQR/median для непараметрического случая.)\\n\")\n",
    "\n",
    "# Вывод-интерпретация по описательной статистике\n",
    "print(\">> Вывод по описательной статистике:\")\n",
    "for g, row in desc.iterrows():\n",
    "    print(f\"   Группа {g}: n={int(row['n'])}, mean={row['mean']:.2f}, median={row['median']:.1f}, sd={row['sd']:.2f}, IQR={row['IQR']:.2f}.\")\n",
    "print(\"   Интерпретация: сравните медианы и IQR — если медианы различаются и IQR невелик, различия могут быть устойчивыми; большие IQR указывают на большую изменчивость внутри группы.\\n\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# 2) Shapiro по группам\n",
    "print(\"2) Shapiro-Wilk (нормальность) по группам:\")\n",
    "shapiro_p = {}\n",
    "for g, sub in data.groupby(group_col):\n",
    "    vals = sub[var].values\n",
    "    if len(vals) >= 3:\n",
    "        stat, p = stats.shapiro(vals if len(vals)<=5000 else np.random.choice(vals, 5000, replace=False))\n",
    "        shapiro_p[g] = p\n",
    "        print(f\"   {g}: n={len(vals)}, W={stat:.4f}, p={p:.4f} ->\", \"нормальность не отвергается\" if p>alpha else \"нормальность отвергается\")\n",
    "    else:\n",
    "        shapiro_p[g] = np.nan\n",
    "        print(f\"   {g}: n={len(vals)} <3 — Shapiro не проводится\")\n",
    "\n",
    "# Вывод-интерпретация по Shapiro\n",
    "print(\"\\n>> Вывод по проверке нормальности (Shapiro-Wilk):\")\n",
    "any_non_normal = False\n",
    "for g, p in shapiro_p.items():\n",
    "    if not np.isnan(p) and p <= alpha:\n",
    "        print(f\"   В группе {g} распределение НЕ нормально (p={p:.4f}).\")\n",
    "        any_non_normal = True\n",
    "    elif not np.isnan(p):\n",
    "        print(f\"   В группе {g} распределение примерно нормально (p={p:.4f}).\")\n",
    "    else:\n",
    "        print(f\"   Для группы {g} недостаточно данных для проверки нормальности.\")\n",
    "if any_non_normal:\n",
    "    print(\"   Интерпретация: поскольку хотя бы в одной группе нормальность нарушена, предпочтителен непараметрический тест (Kruskal-Wallis) для сравнения >2 групп.\\n\")\n",
    "else:\n",
    "    print(\"   Интерпретация: все группы выглядят нормально распределёнными — можно рассмотреть параметрические методы (ANOVA) при выполнении других предпосылок.\\n\")\n",
    "\n",
    "print(\"(Если сомневаетесь, визуализируйте распределения — гистограммы или Q-Q графики.)\\n\")\n",
    "\n",
    "# 3) Levene\n",
    "groups_values = [group[var].values for name, group in data.groupby(group_col)]\n",
    "if len(groups_values) >= 2:\n",
    "    lev_stat, lev_p = stats.levene(*groups_values, center='median')\n",
    "    print(f\"3) Levene (гомогенность дисперсий): stat={lev_stat:.4f}, p={lev_p:.4f} ->\", \"дисперсии однородны\" if lev_p>alpha else \"дисперсии НЕ однородны\")\n",
    "else:\n",
    "    lev_p = np.nan\n",
    "    print(\"3) Levene: недостаточно групп для теста\")\n",
    "\n",
    "# Вывод-интерпретация по Levene\n",
    "print(\"\\n>> Вывод по Levene (гомогенность дисперсий):\")\n",
    "if np.isnan(lev_p):\n",
    "    print(\"   Тест не проводился — недостаточно групп.\")\n",
    "else:\n",
    "    if lev_p > alpha:\n",
    "        print(f\"   Levene p={lev_p:.4f} > {alpha}: дисперсии можно считать однородными — требование homoscedasticity выполнено.\")\n",
    "    else:\n",
    "        print(f\"   Levene p={lev_p:.4f} <= {alpha}: дисперсии отличаются — при использовании ANOVA рассмотрите Welch-ANOVA или непараметрические тесты.\")\n",
    "print(\"   Интерпретация: однородность дисперсий — одно из требований для применения ANOVA; отсутствие однородности уменьшает надёжность классической ANOVA.\\n\")\n",
    "\n",
    "print(\"4) Выбор теста и выполнение:\")\n",
    "groups = sorted(list(data[group_col].unique()))\n",
    "group_vals = [data.loc[data[group_col]==g, var].values for g in groups]\n",
    "\n",
    "all_normal = all([(not np.isnan(shapiro_p[g])) and (shapiro_p[g] > alpha) for g in groups])\n",
    "if all_normal and (not np.isnan(lev_p)) and (lev_p > alpha):\n",
    "    # ANOVA\n",
    "    fstat, pval = stats.f_oneway(*group_vals)\n",
    "    test_used = 'ANOVA'\n",
    "    print(f\"   Применён One-way ANOVA: F = {fstat:.4f}, p = {pval:.6f}\")\n",
    "    # eta squared\n",
    "    grand_mean = np.mean(data[var].values)\n",
    "    ss_between = sum([len(vals)*(np.mean(vals)-grand_mean)**2 for vals in group_vals])\n",
    "    ss_total = sum((data[var].values - grand_mean)**2)\n",
    "    eta2 = ss_between / ss_total if ss_total>0 else np.nan\n",
    "    print(f\"   η² (eta squared) ≈ {eta2:.3f}\")\n",
    "    # Вывод-интерпретация ANOVA\n",
    "    print(\"\\n>> Интерпретация результата ANOVA:\")\n",
    "    if pval < alpha:\n",
    "        print(f\"   p = {pval:.4f} < {alpha}: имеются статистически значимые различия между группами по {var}.\")\n",
    "        print(\"   Дальше: проводить пост-hoc (Tukey HSD или парные t-тесты с поправкой) чтобы узнать, какие пары различаются.\")\n",
    "    else:\n",
    "        print(f\"   p = {pval:.4f} >= {alpha}: статистически значимых различий между группами не обнаружено.\")\n",
    "else:\n",
    "    # Kruskal-Wallis\n",
    "    hstat, pval = stats.kruskal(*group_vals)\n",
    "    test_used = 'Kruskal-Wallis'\n",
    "    print(f\"   Применён Kruskal-Wallis: H = {hstat:.4f}, p = {pval:.6f}\")\n",
    "    # epsilon-squared\n",
    "    k = len(group_vals)\n",
    "    n = sum([len(v) for v in group_vals])\n",
    "    eps2 = (hstat - k + 1) / (n - k) if (n - k) > 0 else np.nan\n",
    "    print(f\"   ε² (epsilon-squared) ≈ {eps2:.3f} (оценка размера эффекта)\")\n",
    "    # Вывод-интерпретация Kruskal\n",
    "    print(\"\\n>> Интерпретация результата Kruskal-Wallis:\")\n",
    "    if pval < alpha:\n",
    "        print(f\"   H = {hstat:.3f}, p = {pval:.4f} < {alpha}: имеются статистически значимые различия между группами по {var}.\")\n",
    "        print(\"   Дальше: проводить пост-hoc парные непараметрические тесты (Mann-Whitney или Dunn) с корректировкой множественных сравнений.\")\n",
    "    else:\n",
    "        print(f\"   H = {hstat:.3f}, p = {pval:.4f} >= {alpha}: статистически значимых различий между группами не обнаружено.\")\n",
    "    print(\"   Интерпретация эффекта (ε²): чем ближе к 0 — тем слабее влияние групп, 0.01 ~ маленький, 0.06 ~ средний, 0.14 ~ большой (ориентировочно).\\n\")\n",
    "\n",
    "# 5) Пост-hoc если значимо\n",
    "if pval < alpha:\n",
    "    print(\"\\n5) Пост-hoc парные сравнения (Mann-Whitney) с Bonferroni коррекцией:\")\n",
    "    pairs = list(itertools.combinations(groups, 2))\n",
    "    m = len(pairs)\n",
    "    for (a,b) in pairs:\n",
    "        va = data.loc[data[group_col]==a, var].values\n",
    "        vb = data.loc[data[group_col]==b, var].values\n",
    "        ustat, up = stats.mannwhitneyu(va, vb, alternative='two-sided')\n",
    "        p_adj = min(up * m, 1.0)\n",
    "        n1, n2 = len(va), len(vb)\n",
    "        mean_u = n1*n2/2\n",
    "        sd_u = math.sqrt(n1*n2*(n1+n2+1)/12)\n",
    "        z = (ustat - mean_u)/sd_u if sd_u>0 else 0\n",
    "        r = z / math.sqrt(n1 + n2)\n",
    "        med_diff = np.median(va) - np.median(vb)\n",
    "        print(f\"   {a} vs {b}: U={ustat:.2f}, p={up:.6f}, p_adj(Bonf)={p_adj:.6f}, median_diff={med_diff:.2f}, approx r={abs(r):.3f}\")\n",
    "        # Дополнительный вывод-интерпретация для каждой пары\n",
    "        if p_adj < alpha:\n",
    "            print(f\"     -> После Bonferroni (p_adj={p_adj:.4f}) разница значима. Медианная разница = {med_diff:.2f}. r≈{abs(r):.3f}.\")\n",
    "            print(\"        Интерпретация: статистически значимая разница между этими возрастными группами; оцените практическую значимость по r и по величине медианной разницы.\")\n",
    "        else:\n",
    "            # если p_adj >= alpha, но исходное p могло быть значимым\n",
    "            if up < alpha:\n",
    "                print(f\"     -> До коррекции p = {up:.4f} < {alpha}, но после Bonferroni p_adj = {p_adj:.4f} >= {alpha} -> различие не выдержало строгой коррекции.\")\n",
    "                print(\"        Интерпретация: возможно слабая/пограничная разница; можно рассмотреть менее консервативные поправки (Holm, BH).\")\n",
    "            else:\n",
    "                print(f\"     -> p = {up:.4f} >= {alpha}: различие статистически незначимо (даже до коррекции).\")\n",
    "    print(\"\\n(Интерпретация: смотрите p_adj; p_adj < 0.05 считается значимым. Обратите внимание на размер эффекта r и на разницу медиан.)\")\n",
    "else:\n",
    "    print(\"\\n5) Пост-hoc не выполняется, т.к. общий тест не значим (p >= 0.05).\")\n",
    "    print(\"   Интерпретация: нет оснований проводить парные сравнения — общая картинка не показывает различий между группами.\\n\")\n",
    "\n",
    "# Финальное краткое заключение, основанное на предыдущих результатах\n",
    "print(\"\\n=== Краткое итоговое заключение ===\")\n",
    "if test_used == 'ANOVA':\n",
    "    if pval < alpha:\n",
    "        print(f\"- ANOVA p = {pval:.4f} < {alpha}: есть различия между возрастными группами по {var}. Проведите post-hoc для выяснения пар.\")\n",
    "    else:\n",
    "        print(f\"- ANOVA p = {pval:.4f} >= {alpha}: значимых различий нет.\")\n",
    "else:\n",
    "    if pval < alpha:\n",
    "        print(f\"- Kruskal-Wallis H = {hstat:.3f}, p = {pval:.4f} < {alpha}: имеются различия между возрастными группами.\")\n",
    "        print(f\"  Размер эффекта ε² ≈ {eps2:.3f} (малый эффект). Рассмотрите post-hoc пары, оцените их практическую значимость.\")\n",
    "    else:\n",
    "        print(f\"- Kruskal-Wallis H = {hstat:.3f}, p = {pval:.4f} >= {alpha}: значимых различий между возрастными группами не выявлено.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b13ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
